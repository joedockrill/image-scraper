{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageScraper",
      "provenance": [],
      "collapsed_sections": [
        "ONIqIEu7VyT4",
        "pvM0imifGwOY"
      ],
      "mount_file_id": "17f9l2cUPK2Yis_4A_YzzeEOqOPafTy5t",
      "authorship_tag": "ABX9TyNIQ74LsaYjtkI9S/49kr71",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joedockrill/image-scraper/blob/master/ImageScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONIqIEu7VyT4",
        "colab_type": "text"
      },
      "source": [
        "# DuckDuckGo and Google Image Scraper\n",
        "\n",
        "This notebook is an image scraper for creating deep learning datasets. Expand this section for help. \n",
        "\n",
        "Hugs & kisses, Joe Dockrill. \n",
        "\n",
        "credits: \n",
        "- [Deepan Prabhu Babu](https://github.com/deepanprabhu/duckduckgo-images-api) for the base DuckDuckGo code\n",
        "- Iegor Timukhin for pointing out that the search constraints param was sitting under my nose the whole time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zga2kYYG1b4R",
        "colab_type": "text"
      },
      "source": [
        "This notebook can scrape from Google and DuckDuckGo but Google is really just an emergency backup in case the DuckDuckGo code breaks at some point.\n",
        "\n",
        "The thumbnails from DDG are larger, the search options are better and the results include the original (full sized) image url which you can have downloaded instead of a thumbnail by using an img_size.\n",
        "\n",
        "Bear in mind that you will get more failures downloading original images because of out of date links, truncated downloads, and sites which ban hot-linking.\n",
        "\n",
        "**Version 2** \\\n",
        "\\\n",
        "You can now constrain DDG searches as follows:\n",
        "\n",
        "```\n",
        "duckduckgo_search(label: str, keywords: str, max_results: int=100,\n",
        "                      img_size: ImgSize=ImgSize.Thumbs, \n",
        "                      img_type: ImgType=ImgType.Photo,\n",
        "                      img_layout: ImgLayout=ImgLayout.Square,\n",
        "                      img_color: ImgColor=ImgColor.All) -> None:\n",
        "\n",
        "img_size can be one of the following: (default=ImgSize.Thumbs)\n",
        "Thumbs, Small, Medium, Large, Wallpaper\n",
        " \n",
        "img_type can be one of the following: (default=ImgType.Photo)\n",
        "All, Photo, Clipart, Gif, Transparent\n",
        "\n",
        "img_layout can be one of the following: (default=ImgLayout.Square)\n",
        "All, Square, Tall, Wide\n",
        "  \n",
        "img_color can be one of the following: (default = ImgColor.All)\n",
        "All, Color, Monochrome, Red, Orange, Yellow, Green, Blue, Purple, Pink, Brown, Black, Gray, Teal, White\n",
        "```\n",
        "\n",
        "Workflow:\n",
        "- Write some search functions in the \"Download your images here\" cell\n",
        "- Run the image cleaner to delete rubbish\n",
        "- Zip it all up\n",
        "- Download it or copy it to Google Drive\n",
        "\n",
        "Images will be downloaded into folders by label name. If you want a one level zip file with all the images at the root just pass an empty string as a label name.\n",
        "\n",
        "If you would prefer to create a CSV file of label/url pairs you can do that at the bottom of the notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvBgNgI7W1lT",
        "colab_type": "text"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVwjN8fnD5kc",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title RUN THIS CELL for code setup.\n",
        "#@markdown If you're new to Colab and you want to see the code, you can select this cell, \n",
        "#@markdown click the ... menu in the top right of the cell then click Form->Hide Form\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import requests\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image as PImage\n",
        "from PIL import ImageDraw as PImageDraw\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from typing import Callable\n",
        "from enum import Enum\n",
        "\n",
        "BASE_FOLDER = \"images\"\n",
        "\n",
        "##########################################################################################\n",
        "# scraping\n",
        "##########################################################################################\n",
        "def google_scrape_urls(keywords: str, max_results: int) -> list:\n",
        "  '''scrape urls from google image search'''\n",
        "  BASE_URL = \"https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&q=\"\n",
        "\n",
        "  HEADERS = {\n",
        "      'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "      'Accept-Encoding': 'none',\n",
        "      'Accept-Language': 'en-US,en;q=0.8',\n",
        "      'Connection': 'keep-alive',\n",
        "  }\n",
        "  \n",
        "  searchurl = BASE_URL + keywords\n",
        "  resp = requests.get(searchurl, headers=HEADERS)\n",
        "  html = resp.text\n",
        "  \n",
        "  soup = BeautifulSoup(html, \"html.parser\")\n",
        "  results = soup.findAll(\"img\", {\"data-src\":True}, limit=max_results)\n",
        "  \n",
        "  links = []\n",
        "  for re in results:\n",
        "    links.append(re[\"data-src\"])\n",
        "\n",
        "  return links  \n",
        "\n",
        "class ImgSize(Enum):\n",
        "  Thumbs=\"\"\n",
        "  Small=\"Small\"\n",
        "  Medium=\"Medium\"\n",
        "  Large=\"Large\"\n",
        "  Wallpaper=\"Wallpaper\"\n",
        "\n",
        "class ImgType(Enum):\n",
        "  All=\"\"\n",
        "  Photo=\"photo\"\n",
        "  Clipart=\"clipart\"\n",
        "  Gif=\"gif\"\n",
        "  Transparent=\"transparent\"\n",
        "\n",
        "class ImgLayout(Enum):\n",
        "  All=\"\"\n",
        "  Square=\"Square\"\n",
        "  Tall=\"Tall\"\n",
        "  Wide=\"Wide\"\n",
        "  \n",
        "class ImgColor(Enum):\n",
        "  All=\"\"\n",
        "  Color=\"color\"\n",
        "  Monochrome=\"Monochrome\"\n",
        "  Red=\"Red\"\n",
        "  Orange=\"Orange\"\n",
        "  Yellow=\"Yellow\"\n",
        "  Green=\"Green\"\n",
        "  Blue=\"Blue\"\n",
        "  Purple=\"Purple\"\n",
        "  Pink=\"Pink\" \n",
        "  Brown=\"Brown\"\n",
        "  Black=\"Black\" \n",
        "  Gray=\"Gray\" \n",
        "  Teal=\"Teal\"\n",
        "  White=\"White\"\n",
        "\n",
        "def duckduckgo_scrape_urls(keywords: str, max_results: int, \n",
        "                           img_size: ImgSize=ImgSize.Thumbs, \n",
        "                           img_type: ImgType=ImgType.Photo,\n",
        "                           img_layout: ImgLayout=ImgLayout.Square,\n",
        "                           img_color: ImgColor=ImgColor.All) -> list:\n",
        "  '''scrape urls from duckduckgo image search'''\n",
        "  BASE_URL = 'https://duckduckgo.com/'\n",
        "  params = {\n",
        "    'q': keywords\n",
        "  };\n",
        "  results = 0\n",
        "  links = []\n",
        "\n",
        "  resp = requests.post(BASE_URL, data=params)\n",
        "  match = re.search(r'vqd=([\\d-]+)\\&', resp.text, re.M|re.I)\n",
        "  assert match is not None, \"Failed to obtain search token\"\n",
        "\n",
        "  HEADERS = {\n",
        "      'authority': 'duckduckgo.com',\n",
        "      'accept': 'application/json, text/javascript, */*; q=0.01',\n",
        "      'sec-fetch-dest': 'empty',\n",
        "      'x-requested-with': 'XMLHttpRequest',\n",
        "      'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36',\n",
        "      'sec-fetch-site': 'same-origin',\n",
        "      'sec-fetch-mode': 'cors',\n",
        "      'referer': 'https://duckduckgo.com/',\n",
        "      'accept-language': 'en-US,en;q=0.9',\n",
        "  }\n",
        "\n",
        "  constraints = \"\"\n",
        "  if(img_size != ImgSize.Thumbs): constraints +=  \"size:\" + img_size.name\n",
        "  constraints += \",\"\n",
        "  if(img_type != ImgType.All): constraints +=  \"type:\" + img_type.name\n",
        "  constraints += \",\"\n",
        "  if(img_layout != ImgLayout.All): constraints +=  \"layout:\" + img_layout.name\n",
        "  constraints += \",\"\n",
        "  if(img_color != ImgColor.All): constraints +=  \"color:\" + img_color.name\n",
        "  \n",
        "  PARAMS = (\n",
        "      ('l', 'us-en'),\n",
        "      ('o', 'json'),\n",
        "      ('q', keywords),\n",
        "      ('vqd', match.group(1)),\n",
        "      ('f', constraints),\n",
        "      ('p', '1'),\n",
        "      ('v7exp', 'a'),\n",
        "  )\n",
        "\n",
        "  requestUrl = BASE_URL + \"i.js\"\n",
        "\n",
        "  while True:\n",
        "      while True:\n",
        "          try:\n",
        "              resp = requests.get(requestUrl, headers=HEADERS, params=PARAMS)\n",
        "              data = json.loads(resp.text)\n",
        "              break\n",
        "          except ValueError as e:\n",
        "              print(\"Hit request throttle, sleeping and retrying\")\n",
        "              time.sleep(5); #seems a lot but ok...\n",
        "              continue\n",
        "\n",
        "      #result[\"thumbnail\"] is normally big enough for most purposes\n",
        "      #result[\"width\"], result[\"height\"] are for the full size img in result[\"image\"]\n",
        "      #result[\"image\"] url to full size img on orig site (so may be less reliable) \n",
        "      #result[\"url\"], result[\"title\"].encode('utf-8') from the page the img came from\n",
        "      \n",
        "      for result in data[\"results\"]:\n",
        "        if(img_size == ImgSize.Thumbs): links.append(result[\"thumbnail\"])\n",
        "        else:                       links.append(result[\"image\"])\n",
        "\n",
        "        if(max_results is not None):\n",
        "          if(len(links) >= max_results) : return links\n",
        "\n",
        "      if \"next\" not in data:\n",
        "          #no next page, all done\n",
        "          return links\n",
        "\n",
        "      requestUrl = BASE_URL + data[\"next\"]\n",
        "\n",
        "##########################################################################################\n",
        "# searching & downloading\n",
        "##########################################################################################\n",
        "def google_search(label: str, keywords: str, max_results: int=100) -> None:\n",
        "  '''run a google search and download the images'''\n",
        "  print(\"Google search: \", keywords)\n",
        "  links = google_scrape_urls(keywords,max_results)\n",
        "  download_urls(label, links)\n",
        "\n",
        "def duckduckgo_search(label: str, keywords: str, max_results: int=100,\n",
        "                           img_size: ImgSize=ImgSize.Thumbs, \n",
        "                           img_type: ImgType=ImgType.Photo,\n",
        "                           img_layout: ImgLayout=ImgLayout.Square,\n",
        "                           img_color: ImgColor=ImgColor.All) -> None:\n",
        "  '''run a duckduckgo search and download the images'''\n",
        "  print(\"Duckduckgo search:\", keywords)\n",
        "  links = duckduckgo_scrape_urls(keywords, max_results, img_size, img_type, img_layout, img_color)\n",
        "  download_urls(label, links)\n",
        "\n",
        "def download_urls(label: str, links: list) -> None:\n",
        "  '''downloads urls into the folder for that label'''\n",
        "  if(len(links) == 0):\n",
        "    print(\"Nothing to download!\"); return\n",
        "\n",
        "  folder = Path(BASE_FOLDER)/label\n",
        "  folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  print(\"Downloading\", len(links), \"results into\", folder)\n",
        "\n",
        "  bar = widgets.IntProgress(0, 0, len(links) - 1)\n",
        "  display(bar)\n",
        "\n",
        "  i = 1\n",
        "  mk_fp = lambda i: folder/(str(i).zfill(3) + \".jpg\")\n",
        "  is_file = lambda i: mk_fp(i).exists()\n",
        "  while is_file(i): i += 1 # don't overwrite previous searches\n",
        "  \n",
        "  for link in links:\n",
        "      try:\n",
        "        resp = requests.get(link)      \n",
        "        fp = mk_fp(i)\n",
        "        fp.write_bytes(resp.content)\n",
        "\n",
        "        try:\n",
        "          img = PImage.open(fp)\n",
        "          img.verify()\n",
        "          img.close()\n",
        "        except Exception as e:\n",
        "          # print(e)\n",
        "          print(fp, \"is invalid\")\n",
        "          fp.unlink()\n",
        "      except:\n",
        "        print(\"Exception occured while retrieving\", link)\n",
        "\n",
        "      i += 1\n",
        "      bar.value += 1\n",
        "\n",
        "  bar.bar_style = \"success\"\n",
        "\n",
        "def save_urls(filename: str, scrape_func: Callable, label: str, keywords: str, max_results: int) -> None:\n",
        "  '''run a search and concat the urls to a csv'''\n",
        "  fp = Path(filename)\n",
        "  if(fp.exists() == False):\n",
        "    df = pd.DataFrame(columns=[\"URL\", \"Label\"])\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "  urls = scrape_func(keywords, max_results)\n",
        "  rows = []\n",
        "\n",
        "  for url in urls:\n",
        "    rows.append({\"URL\":url, \"Label\":label})\n",
        "    \n",
        "  df = pd.concat([pd.read_csv(filename), pd.DataFrame(rows)]) \n",
        "  df.to_csv(filename, index=False)\n",
        "\n",
        "##########################################################################################\n",
        "# moving files around\n",
        "##########################################################################################\n",
        "def download_file(filename: str) -> None:\n",
        "  '''trigger a file download from colab to local system'''\n",
        "  files.download(filename)\n",
        "\n",
        "def transfer_to_drive(filename: str, dest_folder: str=\"Datasets\") -> None:\n",
        "  '''transfer file from colab runtime to google drive'''\n",
        "  drive.mount(\"/content/drive\") \n",
        "  folder = Path(\"/content/drive/My Drive\")/dest_folder\n",
        "  folder.mkdir(parents=True, exist_ok=True)\n",
        "  \n",
        "  shutil.copyfile(filename, str(folder/filename))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTCCj9TS0WVY",
        "colab_type": "text"
      },
      "source": [
        "**Run this cell to delete all image files (to create another dataset or reset)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYwHbopFG63A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r -f images/*"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4dwxx_b0pRV",
        "colab_type": "text"
      },
      "source": [
        "**Download your images here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vw7K4ULGz-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change your zip name and run some searches\n",
        "# help and options are in the hidden cell at the top\n",
        "\n",
        "ZIP_NAME = \"images.zip\" \n",
        "\n",
        "params = {\n",
        "    \"max_results\": 100,             # can go higher, 477 at the time of writing\n",
        "    \"img_size\":    ImgSize.Thumbs, \n",
        "    \"img_type\":    ImgType.Photo,\n",
        "    \"img_layout\":  ImgLayout.Square,\n",
        "    \"img_color\":   ImgColor.All\n",
        "}\n",
        "\n",
        "# EG:\n",
        "# ZIP_NAME = \"Clowns.zip\"\n",
        "# duckduckgo_search(\"Nice\", \"nice clowns\", **params)\n",
        "# duckduckgo_search(\"Scary\", \"scary clowns\", **params)\n",
        "\n",
        "# you can also use google_search() if you prefer or if the ddg code breaks.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWwjDsJDOGrO",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Dataset Cleaner\n",
        "#@markdown Run this cell for a dataset cleaner you can use to get rid of inappropriate\n",
        "#@markdown images before zipping up your dataset.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "##########################################################################################\n",
        "# globals & event handler\n",
        "##########################################################################################\n",
        "ICLN_BATCH_SZ = 8\n",
        "\n",
        "# this may look nauseating and but creating new widgets is literally about 10x slower than \n",
        "# updating existing ones so the ui gets created once and updated forever more\n",
        "icln_folder = None\n",
        "icln_batches = None\n",
        "icln_pager = None\n",
        "icln_grid = None\n",
        "icln_empty_folder = None\n",
        "\n",
        "def delete_on_click(btn):\n",
        "  fn, img, batch, idx = btn.tag\n",
        "  img.value = icln_deleted_img() # display red 'deleted' cross\n",
        "  icln_batches[batch][idx] = \"\"  # so we know it's deleted as we page back & forth\n",
        "  btn.disabled = True\n",
        "  try:    Path(fn).unlink()      # dbl-clicks result in us trying to delete twice\n",
        "  except: pass\n",
        "\n",
        "def paging_on_click(btn):\n",
        "  folder, batch = btn.tag\n",
        "  icln_render_batch(folder, batch)\n",
        "\n",
        "def reload_on_click(btn):\n",
        "  icln_render_batch(icln_folder, 0, force_reload=True)\n",
        "\n",
        "def folder_on_change(change):\n",
        "  if(change[\"type\"] == \"change\" and change[\"name\"] == \"value\"):\n",
        "    icln_render_batch(change[\"new\"], 0)\n",
        "  \n",
        "##########################################################################################\n",
        "# UI creation\n",
        "##########################################################################################\n",
        "def icln_deleted_img():\n",
        "  # creates the red \"deleted\" placeholder cross once, loads it and caches it\n",
        "  DELETED_IMG = \"deleted_img\"\n",
        "  \n",
        "  if(DELETED_IMG not in icln_deleted_img.__dict__):\n",
        "    img = PImage.new(\"RGB\",(150,150), color=\"white\")\n",
        "\n",
        "    draw = PImageDraw.Draw(img)\n",
        "    draw.line((5, 5, 140, 140), fill=\"red\", width=10)\n",
        "    draw.line((5, 140, 140, 5), fill=\"red\", width=10)\n",
        "\n",
        "    # must be able to go from pil to something the widget likes without bouncing off disc :-/\n",
        "    img.save(\"deleted.jpg\")  \n",
        "    icln_deleted_img.__dict__[DELETED_IMG] = open(\"deleted.jpg\", \"rb\").read()\n",
        "\n",
        "  return icln_deleted_img.__dict__[DELETED_IMG]\n",
        "\n",
        "def icln_create_widgets(batch_size):\n",
        "  # create the UI widgets\n",
        "  global icln_pager\n",
        "  global icln_grid\n",
        "  global icln_empty_folder\n",
        "\n",
        "  # image/delete button pairs\n",
        "  display_items = []\n",
        "  for i in range(batch_size):\n",
        "    img = widgets.Image()\n",
        "    img.layout.width=\"150px\"\n",
        "    btn = widgets.Button(description=\"Delete\")\n",
        "    btn.on_click(delete_on_click)\n",
        "    box = widgets.VBox(children=[img,btn])\n",
        "    box.layout.margin = \"5px\"\n",
        "    display_items.append(box)\n",
        "\n",
        "  # paging\n",
        "  btnFirst = widgets.Button(description=\"|<<\") \n",
        "  btnPrev = widgets.Button(description=\"<<\")\n",
        "  lblPage = widgets.Label(value=\"Page NNN of KKK\")\n",
        "  lblPage.layout = widgets.Layout(display=\"flex\", justify_content=\"center\", width=\"100px\")\n",
        "  btnNext = widgets.Button(description=\">>\")\n",
        "  btnLast = widgets.Button(description=\">>|\")\n",
        "  \n",
        "  pgbtns = [btnFirst, btnPrev, btnNext, btnLast]\n",
        "  for btn in pgbtns: btn.on_click(paging_on_click)\n",
        "  for btn in pgbtns: btn.layout.width = \"60px\"\n",
        "\n",
        "  # folder drop down\n",
        "  root = Path(BASE_FOLDER)\n",
        "  folders = [f.stem for f in root.glob(\"*\") if (f.is_dir() and f.stem[0] != \".\")]\n",
        "  folders.sort()\n",
        "  rootfiles = [f for f in root.glob(\"*\") if f.is_file()]\n",
        "  if(len(rootfiles) > 0): folders = [\"/\"] + folders\n",
        "  ddlFolder = widgets.Dropdown(options=folders, description=\"Folder: \")\n",
        "  ddlFolder.observe(folder_on_change)\n",
        "\n",
        "  # reload button\n",
        "  btnReload = widgets.Button(description=\"â†»\")\n",
        "  btnReload.layout = widgets.Layout(width=\"40px\", margin=\"0px 0px 0px 10px\")\n",
        "  btnReload.on_click(reload_on_click)\n",
        "\n",
        "  # plug it all in and display\n",
        "  icln_pager = widgets.HBox(children=[btnFirst, btnPrev, lblPage, btnNext, btnLast, \n",
        "                                      ddlFolder, btnReload])  \n",
        "  icln_grid = widgets.GridBox(display_items, \n",
        "                              layout=widgets.Layout(grid_template_columns=\"repeat(4, 25%)\",\n",
        "                                                    margin=\"15px\"))\n",
        "  icln_empty_folder = widgets.HTML(value=\"<h2>No images left to display in this folder.</h2>\")\n",
        "  icln_empty_folder.layout.visibility = \"hidden\"\n",
        "\n",
        "  display(icln_pager)\n",
        "  display(icln_empty_folder)\n",
        "  display(icln_grid)\n",
        "  \n",
        "##########################################################################################\n",
        "# UI rendering\n",
        "##########################################################################################\n",
        "def icln_render_batch(folder, batch, force_reload=False):\n",
        "  global icln_folder\n",
        "  global icln_batches\n",
        "  global icln_pager\n",
        "  global icln_grid\n",
        "\n",
        "  if(folder == \"/\"): folder = \"\"\n",
        "  path = Path(BASE_FOLDER)/folder\n",
        "\n",
        "  if((icln_folder != folder) or (force_reload)): \n",
        "    # get the files, split into batches  \n",
        "    files = list(path.glob(\"*.jpg\"))\n",
        "    icln_batches = [files[i:i + ICLN_BATCH_SZ] for i in range(0, len(files), ICLN_BATCH_SZ)]\n",
        "    icln_folder = folder\n",
        "\n",
        "    if(len(files) == 0):\n",
        "      # fail gracefully if they've deleted every image in this folder\n",
        "      icln_empty_folder.layout.visibility = \"visible\"\n",
        "      # icln_grid.layout.visibility = \"hidden\" <-- doesn't work :-@\n",
        "      for child in icln_grid.children: child.layout.visibility = \"hidden\"\n",
        "      btnFirst, btnPrev, lblPage, btnNext, btnLast,_,_ = icln_pager.children\n",
        "      lblPage.value = \"Page 0 of 0\"\n",
        "      for btn in [btnFirst, btnPrev, btnNext, btnLast]: btn.disabled = True\n",
        "      return\n",
        "    else:\n",
        "      icln_empty_folder.layout.visibility = \"hidden\"\n",
        "      icln_grid.layout.visibility = \"visible\"\n",
        "\n",
        "  # display the images\n",
        "  for i, fp in enumerate(icln_batches[batch]):\n",
        "    icln_grid.children[i].layout.visibility = \"visible\"\n",
        "    img = icln_grid.children[i].children[0]\n",
        "    btn = icln_grid.children[i].children[1]\n",
        "\n",
        "    if(fp == \"\"):\n",
        "      img.value = icln_deleted_img()\n",
        "      btn.disabled = True\n",
        "    else:\n",
        "      img.value = open(fp, \"rb\").read()\n",
        "      btn.tag = (fp, img, batch, i)\n",
        "      btn.disabled = False\n",
        "\n",
        "  if(len(icln_batches[batch]) < ICLN_BATCH_SZ):\n",
        "    # partial batch on the last page, hide the rest of the grid\n",
        "    for i in range(len(icln_batches[batch]), ICLN_BATCH_SZ):\n",
        "      icln_grid.children[i].layout.visibility = \"hidden\"\n",
        "    \n",
        "  # update the paging controls\n",
        "  btnFirst, btnPrev, lblPage, btnNext, btnLast,_,_ = icln_pager.children\n",
        "  btnFirst.tag = (folder, 0) \n",
        "  btnPrev.tag = (folder, max(0, batch-1)) \n",
        "  btnNext.tag = (folder, min(len(icln_batches)-1, batch+1)) \n",
        "  btnLast.tag = (folder, len(icln_batches)-1) \n",
        "  lblPage.value = \"Page {} of {}\".format(batch+1, len(icln_batches))\n",
        "  for btn in [btnFirst, btnPrev, btnNext, btnLast]: btn.disabled = btn.tag[1] == batch\n",
        "\n",
        "##########################################################################################\n",
        "# and to actually create the UI and render the first folder in the list:\n",
        "##########################################################################################\n",
        "icln_create_widgets(ICLN_BATCH_SZ)\n",
        "_,_,_,_,_,ddlFolder,_ = icln_pager.children\n",
        "icln_render_batch(ddlFolder.value, 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6KTdjEY0Fix",
        "colab_type": "text"
      },
      "source": [
        "**Run this cell to create a zip file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8CT2yVzfZXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -f {ZIP_NAME}\n",
        "!zip -q -r {ZIP_NAME} images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmtxy9LX2M1J",
        "colab_type": "text"
      },
      "source": [
        "**Run one of these cells to get your zip file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmnndlPN1yTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download to your local system\n",
        "download_file(ZIP_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BfkU4_u2kdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy to google drive \n",
        "transfer_to_drive(ZIP_NAME, dest_folder=\"Datasets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvM0imifGwOY",
        "colab_type": "text"
      },
      "source": [
        "# Create a CSV file of URLs\n",
        "\n",
        "If you'd rather distribute a file with the image URLs and labels and have people download the images themselves you can do so here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_VQvB9KG0v-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CSV_NAME = \"images.csv\" #change this to something more meaningful\n",
        "\n",
        "!rm -f {CSV_NAME}\n",
        "\n",
        "# save_urls(CSV_NAME, duckduckgo_scrape_urls, \"dogs\", \"dogs or puppies\", 10)\n",
        "# save_urls(CSV_NAME, duckduckgo_scrape_urls, \"cats\", \"cats or kittens\", 10)\n",
        "# save_urls(CSV_NAME, duckduckgo_scrape_urls, \"rabbits\", \"rabbits sitting in mugs\", 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e3qXa6FLPfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download to your local system\n",
        "download_file(CSV_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e2GI-iegG3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy to google drive \n",
        "transfer_to_drive(CSV_NAME, dest_folder=\"Datasets\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}